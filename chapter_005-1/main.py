import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

# models
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic


import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse

SUMMARISE_PROMPT = """ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã¤ã„ã¦ã€å†…å®¹ã‚’300æ–‡å­—ç¨‹åº¦ã§ã‚ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ãã ã•ã„


======

{content}

======

æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„
"""

def init_page():
    st.set_page_config(
        page_title="Website Summarizer",
        page_icon="ğŸ˜Š"
    )
    st.header("Website Summarizer ğŸ˜­")
    st.sidebar.title("Options")

def select_model():
    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.01ã¨ã™ã‚‹
    temperature = st.sidebar.slider(
        "Temperature", min_value=0.0, max_value=2.0, value=0.0, step=0.01)
    
    models = ["gpt-4o-mini", "claude-3-5-sonnet-20240620"]
    model = st.sidebar.selectbox("Choose a Model", models)
    if model == "gpt-4o-mini":
        st.session_state.model_name = "gpt-4o-mini"
        return ChatOpenAI(
            temperature=temperature,
            model=st.session_state.model_name
            )
    elif model == "claude-3-5-sonnet-20240620":
        st.session_state.model_name = "claude-3-5-sonnet-20240620"
        return ChatAnthropic(
            temperature=temperature,
            model=st.session_state.model_name
            )
    
def init_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("system", SUMMARISE_PROMPT),
    ])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain

def validate_url(url):
    """ URLãŒæœ‰åŠ¹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹é–¢æ•° """
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False

def get_content(url):
    try:
        with st.spinner("Fetching Website..."):
            response = requests.get(url)
            soup = BeautifulSoup(response.text, "html.parser")
            # ãªã‚‹ã¹ãæœ¬æ–‡ã®å¯èƒ½æ€§ãŒé«˜ã„è¦ç´ ã‚’å–å¾—ã™ã‚‹
            if soup.main:
                return soup.main.get_text()
            elif soup.article:
                return soup.article.get_text()
            else:
                return soup.body.get_text()
    except:
        st.write(traceback.format_exc()) # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ã‚¨ãƒ©ãƒ¼å†…å®¹ã‚’è¡¨ç¤º
        return None
    
def main():
    init_page()
    chain = init_chain()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    # ä»£å…¥ã¨æ¯”è¼ƒã‚’åŒæ™‚ã«è¡Œã£ã¦ã„ã‚‹(nullãƒã‚§ãƒƒã‚¯ã—ã¦ã‚‹)
    if url := st.text_input("URL : ", key="input"):
        is_valid_url = validate_url(url)

        if not is_valid_url:
            st.write('Please input valid url')
        else:
            if content := get_content(url):
                st.markdown("## Summary")
                st.write_stream(chain.stream({"content": content}))
                st.markdown("---")
                st.markdown("## Original Text")
                st.write(content)
    
    # ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆã¯ç¬¬3ç« ã¨åŒã˜å®Ÿè£…ã‚’è¿½åŠ ã—ã¦ãã ã•ã„(ä»Šå›ã¯å®Ÿè£…ãªã—)
    # calc_and_display_cost()

if __name__ == "__main__":
    main()